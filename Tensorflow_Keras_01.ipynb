{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "**Keras** is a high-level API to build and train deep learning models. It's used for fast prototyping, advanced research, and production, with three key advantages:\n",
    "- 1 User friendly\n",
    "Keras has a simple, consistent interface optimized for common use cases. It provides clear and actionable feedback for user errors.\n",
    "- 2 Modular and composable\n",
    "Keras models are made by connecting configurable building blocks together, with few restrictions.\n",
    "- 3 Easy to extend\n",
    "Write custom building blocks to express new ideas for research. Create new layers, loss functions, and develop state-of-the-art models.\n",
    "\n",
    "References:\n",
    "- https://keras.io/;\n",
    "- https://www.tensorflow.org/guide/keras\n",
    "\n",
    "**Note**: `tf.keras` is TensorFlow's implementation of the [Keras API specification](https://keras.io/). This is a high-level API to build and train models that includes first-class support for TensorFlow-specific functionality, such as `eager execution`, `tf.data pipelines`, and `Estimators`. `tf.keras` makes TensorFlow easier to use without sacrificing flexibility and performance.\n",
    "\n",
    "To get started, import tf.keras as part of your TensorFlow program setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cui\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras` can run any Keras-compatible code, but keep in mind:\n",
    "- The `tf.keras` version in the latest TensorFlow release might not be the same as the latest keras version from PyPI. Check `tf.keras.version`.\n",
    "- When saving a model's weights, `tf.keras` defaults to the checkpoint format. Pass `save_format='h5'` to use HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__) # the current version is 2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple model\n",
    "\n",
    "### Sequential model\n",
    "In Keras, you assemble layers to build models. A model is (usually) a graph of layers. The most common type of model is a stack of layers: the `tf.keras.Sequential` model.\n",
    "To build a simple, fully-connected network (i.e. multi-layer perceptron):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the layers\n",
    "There are many `tf.keras.layers` available with some common constructor parameters:\n",
    "- **activation**: Set the activation function for the layer. This parameter is specified by the name of a built-in function or as a callable object. By default, no activation is applied.\n",
    "- **kernel_initializer and bias_initializer**: The initialization schemes that create the layer's weights (kernel and bias). This parameter is a name or a callable object. This defaults to the \"Glorot uniform\" initializer.\n",
    "- **kernel_regularizer and bias_regularizer**: The regularization schemes that apply the layer's weights (kernel and bias), such as L1 or L2 regularization. By default, no regularization is applied.\n",
    "The following instantiates `tf.keras.layers.Dense layers` using constructor arguments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=keras.regularizers.l1(0.01))\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=keras.initializers.constant(2.0))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_3 [] []\n",
      "dense_4 [] []\n",
      "dense_5 [] []\n",
      "dense_6 [] []\n",
      "dense_7 [] []\n",
      "dense_8 [] []\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential()\n",
    "# create a sigmoid layer:\n",
    "model2.add(keras.layers.Dense(64, activation ='sigmoid'))\n",
    "# or \n",
    "model2.add(keras.layers.Dense(64, activation = tf.sigmoid))\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "model2.add(keras.layers.Dense(64, kernel_regularizer = keras.regularizers.l1(0.001)))\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "model2.add(keras.layers.Dense(64, bias_regularizer=keras.regularizers.l2(0.01)))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "model2.add(keras.layers.Dense(64, kernel_initializer='orthogonal'))\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "model2.add(keras.layers.Dense(64, bias_initializer=keras.initializers.constant(2.0)))\n",
    "\n",
    "for layer in model2.layers:\n",
    "    print(layer.name, layer.inbound_nodes, layer.outbound_nodes)\n",
    "\n",
    "# print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate\n",
    "### Set up training\n",
    "\n",
    "After the model is constructed, configure its learning process by calling the compile method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.Model.compile` takes three important arguments:\n",
    "- **optimizer**: This object specifies the training procedure. Pass it optimizer instances from the `tf.train` module, such as `AdamOptimizer`, `RMSPropOptimizer`, or `GradientDescentOptimizer`.\n",
    "- **loss**: The function to minimize during optimization. Common choices include mean square error (`mse`), `categorical_crossentropy`, and `binary_crossentropy`. Loss functions are specified by name or by passing a callable object from the `tf.keras.losses` module.\n",
    "- **metrics**: Used to monitor training. These are string names or callables from the `tf.keras.metrics` module.\n",
    "\n",
    "The following shows a few examples of configuring a model for training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(0.01),\n",
    "              loss = 'mse', # mean squared error\n",
    "              metrics = ['mae']) # mean absolute error\n",
    "# configure a model for categorical classification.\n",
    "model.compile(optimizer = tf.train.RMSPropOptimizer(0.01),\n",
    "              loss = keras.losses.categorical_crossentropy,\n",
    "              metrics = [keras.metrics.categorical_accuracy])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has never been called, thus its weights have not yet been created, so no summary can be displayed. Build the model first (e.g. by calling it on some data).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3caefa261807>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1544\u001b[0m     \"\"\"\n\u001b[0;32m   1545\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1546\u001b[1;33m       raise ValueError('This model has never been called, thus its weights '\n\u001b[0m\u001b[0;32m   1547\u001b[0m                        \u001b[1;34m'have not yet been created, so no summary can be '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m                        \u001b[1;34m'displayed. Build the model first '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has never been called, thus its weights have not yet been created, so no summary can be displayed. Build the model first (e.g. by calling it on some data)."
     ]
    }
   ],
   "source": [
    " print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Numpy data\n",
    "For small datasets, use in-memory [`NumPy`](https://www.numpy.org/) arrays to train and evaluate a model. The model is \"fit\" to the training data using the fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 266us/step - loss: 11.5882 - acc: 0.0970\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 11.5540 - acc: 0.1000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 11.5455 - acc: 0.1130\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 11.5397 - acc: 0.1050\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 11.5349 - acc: 0.1290\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 11.5303 - acc: 0.1370\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 11.5255 - acc: 0.1360\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 11.5218 - acc: 0.1310\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 11.5172 - acc: 0.1440\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5119 - acc: 0.1590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d88a26ffd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    " print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.Model.fit` takes three improtant arguments:\n",
    "- `epochs`: Training is structured into epochs. An epoch is one iteration over the entirre input data (this is done in smaller batches).\n",
    "- `batch_size`: When passed NumPy data, the model slices the data into smaller batches and iterates over these batches during training. This integer specifies the size of each batch.Be ware that the last batch may be smaller if the total number of samples is not divisible by the batch size.\n",
    "- `validation_data`: When prototping a model, you want to easily monitor its performance on some validaiton data. Passing this argument - a tuple of inputs and lables - allows the model to display the loss and metrics in inference mode for the passed data, at the end of each epoch.\n",
    "\n",
    "Here's an example using `validation_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 11.5485 - acc: 0.1060 - val_loss: 11.4838 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 11.5352 - acc: 0.1180 - val_loss: 11.4854 - val_acc: 0.1100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5288 - acc: 0.1220 - val_loss: 11.4865 - val_acc: 0.1200\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 11.5236 - acc: 0.1270 - val_loss: 11.4833 - val_acc: 0.1000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 11.5179 - acc: 0.1410 - val_loss: 11.4872 - val_acc: 0.0900\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 11.5125 - acc: 0.1310 - val_loss: 11.4868 - val_acc: 0.0700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 11.5089 - acc: 0.1420 - val_loss: 11.4915 - val_acc: 0.0900\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.8804 - acc: 0.06 - 0s 17us/step - loss: 11.5040 - acc: 0.1530 - val_loss: 11.4919 - val_acc: 0.0900\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 11.5004 - acc: 0.1280 - val_loss: 11.4920 - val_acc: 0.0900\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 11.4952 - acc: 0.1500 - val_loss: 11.4971 - val_acc: 0.0800\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input tf.data datasets\n",
    "Use the [Datasets API](https://www.tensorflow.org/guide/datasets) to scale to large datasets or multi-device training. Pass a `tf.data.Dataset` instance to the `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4860 - acc: 0.1688\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 973us/step - loss: 11.5315 - acc: 0.1604\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5155 - acc: 0.1698\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4843 - acc: 0.1677\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4881 - acc: 0.1823\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 957us/step - loss: 11.4988 - acc: 0.1833\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4839 - acc: 0.1792\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 604us/step - loss: 11.4895 - acc: 0.1885\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4900 - acc: 0.1948\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 698us/step - loss: 11.5085 - acc: 0.1885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d89015a6d8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data,labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the fit method uses the `steps_per_epoch` argument—this is the number of training steps the model runs before it moves to the next epoch. Since the `Dataset` yields batches of data, this snippet does not require a batch_size.\n",
    "\n",
    "Datasets can also be used for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 11.4433 - acc: 0.1906 - val_loss: 11.5281 - val_acc: 0.0521\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4828 - acc: 0.2177 - val_loss: 11.4326 - val_acc: 0.0417\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4672 - acc: 0.2156 - val_loss: 11.3641 - val_acc: 0.0208\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4363 - acc: 0.2146 - val_loss: 11.5783 - val_acc: 0.0521\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4387 - acc: 0.2229 - val_loss: 11.5463 - val_acc: 0.0625\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4489 - acc: 0.2198 - val_loss: 11.4307 - val_acc: 0.0625\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 879us/step - loss: 11.4340 - acc: 0.2188 - val_loss: 11.3477 - val_acc: 0.0417\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 975us/step - loss: 11.4402 - acc: 0.2240 - val_loss: 11.5725 - val_acc: 0.0729\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4414 - acc: 0.2146 - val_loss: 11.5508 - val_acc: 0.0833\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4587 - acc: 0.2177 - val_loss: 11.4466 - val_acc: 0.0521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d8901a66a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and predict\n",
    "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use `NumPy` data and a `tf.data.Dataset`.\n",
    "\n",
    "To evaluate the inference-mode loss and metrics for the data provided:\n",
    "\n",
    "```python\n",
    "model.evaluate(x, y, batch_size=32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.39530970255534, 0.23229166666666667]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to predict the output of the last layer in inference for the data provided, as a `NumPy` array:\n",
    "\n",
    "```python\n",
    "model.predict(x, batch_size=32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08554967, 0.09201679, 0.0918855 , ..., 0.10770091, 0.07330296,\n",
       "        0.09502364],\n",
       "       [0.07582473, 0.07689644, 0.12348803, ..., 0.09331267, 0.08332489,\n",
       "        0.11231889],\n",
       "       [0.09682094, 0.09555242, 0.1254478 , ..., 0.0874647 , 0.08615924,\n",
       "        0.09156223],\n",
       "       ...,\n",
       "       [0.11067551, 0.11609698, 0.08456248, ..., 0.10321286, 0.09033251,\n",
       "        0.09206989],\n",
       "       [0.10804565, 0.09348496, 0.12605694, ..., 0.0802942 , 0.08369122,\n",
       "        0.11313645],\n",
       "       [0.11168894, 0.09263443, 0.12812832, ..., 0.09883527, 0.10700932,\n",
       "        0.09209047]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build advanced models\n",
    "### Functional API\n",
    "\n",
    "The `tf.keras.Sequential` model is a simple stack of layers that cannot represent arbitrary models. Use the `Keras functional API` to build complex model topologies such as:\n",
    "- Multi-input models,\n",
    "- Multi-output models,\n",
    "- Models with shared layers (the same layer called several times),\n",
    "- Models with non-sequential data flows (e.g. residual connections).\n",
    "\n",
    "Building a model with the functional API works like this:\n",
    "1. A layer instance is callable and returns a tensor.\n",
    "2. Input tensors and output tensors are used to define a `tf.keras.Model` instance.\n",
    "3. This model is trained just like the `Sequential` model.\n",
    "\n",
    "The following example uses the functional API to build a simple, fully-connected network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 229us/step - loss: 11.7467 - acc: 0.0960\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 11.5926 - acc: 0.1030\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 11.5596 - acc: 0.1010\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 11.5469 - acc: 0.0980\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 11.5376 - acc: 0.1150\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "OutputLayer (Dense)          (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,922\n",
      "Trainable params: 6,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32,))  # Returns a placeholder tensor\n",
    "\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax', name = 'OutputLayer')(x)\n",
    "\n",
    "# Instantiate the model given inputs and outputs.\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model subclassing\n",
    "Build a fully-customizable model by subclassing `tf.keras.Model` and defining your own forward pass. Create layers in the `__init__` method and set them as attributes of the class instance. Define the forward pass in the `call` method.\n",
    "\n",
    "Model subclassing is particularly useful when `eager execution` is enabled since the forward pass can be written imperatively.\n",
    "\n",
    "**Key Point**: Use the right API for the job. While model subclassing offers flexibility, it comes at a cost of greater complexity and more opportunities for user errors. If possible, prefer the functional API.\n",
    "\n",
    "The following example shows a subclassed `tf.keras.Model` using a custom forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 269us/step - loss: 11.6711 - acc: 0.1080\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 11.6212 - acc: 0.1030\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 11.5670 - acc: 0.0880\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 11.5503 - acc: 0.1010\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 11.5431 - acc: 0.0920\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  330       \n",
      "=================================================================\n",
      "Total params: 1,386\n",
      "Trainable params: 1,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        # define your layers here.\n",
    "        self.dense_1 = keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define your forward pass here,\n",
    "        # using layers you previously defined (in `__init__`).\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)        \n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # You need to override this function if you want to use the subclassed model\n",
    "        # as part of a functional-style model.\n",
    "        # Otherwise, this method is optional.\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "\n",
    "# Instantiates the subclassed model.\n",
    "model = MyModel(num_classes=10)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)    \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom layers\n",
    "Create a custom layer by subclassing `tf.keras.layers.Layer` and implementing the following methods:\n",
    "- `build`: Create the weights of the layer. Add weights with the `add_weight` method.\n",
    "- `call`: Define the forward pass.\n",
    "- `compute_output_shape`: Specify how to compute the output shape of the layer given the input shape.\n",
    "- Optionally, a layer can be serialized by implementing the `get_config` method and the from_config class method.\n",
    "\n",
    "Here's an example of a custom layer that implements a `matmul` of an input with a kernel matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 185us/step - loss: 13.4339 - acc: 0.1050\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 12.7703 - acc: 0.0990\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 12.2430 - acc: 0.0950\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 12.0468 - acc: 0.1010\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 11.9945 - acc: 0.1000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_1 (MyLayer)         (None, 10)                320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class MyLayer(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        # Be sure to call this at the end\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "# Create a model using the custom layer\n",
    "model = keras.Sequential([MyLayer(10),\n",
    "                          keras.layers.Activation('softmax')])\n",
    "\n",
    "# The compile step specifies the training configuration\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
