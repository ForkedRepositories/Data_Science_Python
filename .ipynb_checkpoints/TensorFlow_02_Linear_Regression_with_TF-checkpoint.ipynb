{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow operations (also called **ops** for short) can take any number of inputs and produce any number of outputs. For example, the addition and multiplication ops each take two inputs and produce one output. \n",
    "\n",
    "For example, the addition and multiplication ops each take two inputs and produce one output. Constants and variables take no input (they are called **source ops**). \n",
    "\n",
    "The inputs and outputs are **multidimensional arrays**, called `tensors` (hence the name **“tensor flow”**).\n",
    "\n",
    "Just like NumPy arrays, tensors have a type and a shape. In fact, in the Python API tensors are simply represented by NumPy ndarrays. They typically contain floats, but you can also use them to carry strings (arbitrary byte arrays)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the following code manipulates 2D arrays to perform Linear Regression on the California housing data‐ set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script type=\"text/javascript\" src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default\"></script>\n",
    "\n",
    "It starts by fetching the dataset; then it adds an extra bias input feature (`x0 = 1`) to all training instances (it does so using NumPy so it runs immediately); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caihaocui/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "m,n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it creates two TensorFlow constant nodes, `X` and `y`, to hold this data and the targets, and it uses some of the matrix operations provided by TensorFlow to define theta. \n",
    "\n",
    "These matrix functions—`transpose()`, `matmul()`, and `matrix_inverse()`— are self-explanatory, but as usual they do not perform any computations immediately; instead, they create nodes in the graph that will perform them when the graph is run. \n",
    "\n",
    "You may recognize that the definition of `theta` corresponds to the Normal Equation\n",
    "$$\\theta = (X^{T} X)^{-1}X^{T}y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = 'y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT), y)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that housing.target is a 1D array, but we need to reshape it to a column vector to compute theta. \n",
    "Recall that NumPy’s reshape() function accepts –1 (meaning “unspecified”) for one of the dimensions: that dimension will be computed based on the array’s length and the remaining dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640,)\n",
      "(20640, 1)\n"
     ]
    }
   ],
   "source": [
    "print(housing.target.shape)\n",
    "print(housing.target.reshape(-1,1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the code creates a session and uses it to evaluate theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7185181e+01]\n",
      " [ 4.3633747e-01]\n",
      " [ 9.3952334e-03]\n",
      " [-1.0711310e-01]\n",
      " [ 6.4479220e-01]\n",
      " [-4.0338000e-06]\n",
      " [-3.7813708e-03]\n",
      " [-4.2348403e-01]\n",
      " [-4.3721911e-01]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main benefit of this code versus computing the Normal Equation directly using NumPy is that TensorFlow will automatically run this on your GPU card if you have one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
